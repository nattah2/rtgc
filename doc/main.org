#+title: Main

* Background Info - Basic
An object is called garbage at some point during execution if it will never be used again.
#+begin_src c
int main() {
        Object x, y;
        x = new Object();
        y = new Object();
        /* Point A */
        x.doSomething();
        y.doSomething();
        /* Point B */
        y = new Object();
        /* Point C */
}
#+end_src
In general, it is undecidable whether an object is garbage.

* Types of garbage collection
An incremental collector is one that runs concurrently with the program.
● A stop-the-world collector pauses program execution to look for garbage

A compacting collector is one that moves objects around in memory.
● A non-compacting collector is one that leaves all objects where they originated

* Stacatto
the collec tor’s work is divided into three main phases: marking reachable
objects, sweeping away unmarked objects, and compacting frag-
mented objects into contiguous pages

concurrent marking

concurrent compact

latency_{stw} = a * size_{heap} * memrefs_{stw} memlatency_{avg}

* My Notes v1.
Almost all modern programming languages make use of dynamic memory allocation. This allows objects to be allocated and deallocated even if their total size was not known at the time that the program was compiled, and if their lifetime may exceed that of the subroutine activation1 that allocated them.
A dynamically allocated object is stored in a heap, rather than on the stack (in the activation record or stack frame of the procedure that allocated it) or statically (whereby the name of an object is bound to a storage location known at compile or link time).
Heap allocated objects are accessed through references. Typically, a reference is a pointer to
the object (that is, the address in memory of the object). However, a reference may alterna-
tively refer to an object only indirectly, for instance through a handle which in turn points
to the object.

The second kind of error is that the programmer may fail to free an object no longer
required by the program, leading to a memory leak

This is even more problematic for concurrent programming when two or more threads may reference an object. With the increasing ubiquity of multicore processors, considerable effort has gone into the construction of libraries of data structures that are thread-safe

Speaking at a security conference in February 2019, a Microsoft engineer said that around 70% of all security updates released for Microsoft products over the past twelve years were fixes for memory safety vulnerabilities.

Automatic dynamic memory management resolves many of these issues. Garbage collection
(GC) prevents creation of dangling pointers: an object is only reclaimed when there is no
pointer to it from a reachable object.

The key argument in favour of garbage collection is not just that it simplifies coding
— which it does — but that it uncouples the problem of memory management from inter-
faces, rather than scattering it throughout the code. It improves reusability. This is why
garbage collection, in one form or another, has been a requirement of almost all modern
languages (see Table 1.1).

More recently, Cai et al. [2022] developed a method to identify a lower bound for the
overhead of garbage collection. For a given application, they distil out explicit garbage
collection costs (such as costs during stop-the-world pauses), and repeat this to find the
minimum distilled cost from running the application with different collectors

Djikstra - mutator executes application code, which allocates new objects and mutates the
object graph by changing reference fields so that they refer to different destination
objects. These reference fields may be contained in heap objects as well as other
places known as roots, such as static variables, thread stacks and so on. As a result of

such reference updates, any object can end up disconnected from the roots, that is,
unreachable by following any sequence of edges from the roots.
• The collector executes garbage collection code, which discovers unreachable objects
and reclaims their storage.

* My Notes - C
** Multithreading
A lock that ensures only one thread can access a shared resource.
#+begin_src cpp
#include <pthread.h>
pthread_mutex_t heap_lock = PTHREAD_MUTEX_INITIALIZER;
pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;

// Dynamic initialization (runtime, use pthread_mutex_init)
pthread_mutex_t mutex;
pthread_mutex_init(&mutex, NULL);  // NULL = default attributes
pthread_mutex_destroy(&mutex);  // Free resources
#+end_src
#+begin_src cpp
#include <stdio.h>
#include <pthread.h>

int counter = 0;
pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;

void* increment(void* arg) {
    for (int i = 0; i < 100000; i++) {
        pthread_mutex_lock(&mutex);
        counter++;  // Critical section
        pthread_mutex_unlock(&mutex);
    }
    return NULL;
}

int main() {
    pthread_t t1, t2;
    pthread_create(&t1, NULL, increment, NULL);
    pthread_create(&t2, NULL, increment, NULL);
    pthread_join(t1, NULL);
    pthread_join(t2, NULL);
    printf("Counter: %d\n", counter);  // Correctly prints 200000
    return 0;
}
#+end_src
** Thread Local Storage
** Lock-Free Techniques
Atomic Operations
